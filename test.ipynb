{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CpxfkuI5XeV"
   },
   "source": [
    "#### 경로 설정 & 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'data/'\n",
    "model_save_name = 'model_v17.1_0202_best_f1(0.95324).pt'\n",
    "submission_file_name = 'submission_file_name.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2l75gjNw0dEf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from skimage.transform import warp, rotate, AffineTransform, ProjectiveTransform\n",
    "from skimage.util import random_noise\n",
    "from scipy import ndimage\n",
    "\n",
    "import timm\n",
    "from timm.data.auto_augment import auto_augment_transform\n",
    "from timm.data.auto_augment import rand_augment_transform\n",
    "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
    "from PIL import Image\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7H100yJ1iTr"
   },
   "outputs": [],
   "source": [
    "train_csv = sorted(glob('data/train/*/*.csv'))\n",
    "train_jpg = sorted(glob('data/train/*/*.jpg'))\n",
    "train_json = sorted(glob('data/train/*/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2k7OI3TMSjC"
   },
   "outputs": [],
   "source": [
    "test_csv = sorted(glob('data/test/*/*.csv'))\n",
    "test_jpg = sorted(glob('data/test/*/*.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUHhP_gDIJFs"
   },
   "source": [
    "#### 데이터 전처리 & 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiSRUlExHQt4"
   },
   "source": [
    "- 환경 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY4ngEfNXyxY"
   },
   "outputs": [],
   "source": [
    "max_len = 600\n",
    "csv_features = ['내부 온도 1 평균', '내부 습도 1 평균', '내부 이슬점 평균']\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfzWFkEc98fo",
    "outputId": "8a2baf12-fa7b-47bc-83ca-567cd0331c90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5766/5766 [01:17<00:00, 74.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(num_row, num_feat): (1772360, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_env = pd.read_csv(train_csv[0])[csv_features]\n",
    "first_env = first_env.replace('-',np.nan)\n",
    "first_env = pd.DataFrame(imputer.fit_transform(first_env))\n",
    "env_concat = first_env.astype(float).diff().iloc[1:].values\n",
    "for csv_path in tqdm(train_csv[1:]):\n",
    "    tmp = pd.read_csv(csv_path)[csv_features]\n",
    "    tmp = tmp.replace('-', np.nan)\n",
    "    tmp = pd.DataFrame(imputer.fit_transform(tmp))\n",
    "    tmp = tmp.astype(float).diff().replace(np.nan, 0.).values\n",
    "    if len(tmp) <= 1:\n",
    "        continue\n",
    "    env_concat = np.vstack((env_concat, tmp[1:]))\n",
    "print('\\n(num_row, num_feat): ', env_concat.shape, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOCglEs7GJSo"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler().fit(env_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQh1ip4KInzH"
   },
   "outputs": [],
   "source": [
    "def prepro_csv(csv_file, max_len=200):\n",
    "    df = pd.read_csv(csv_file)[csv_features]\n",
    "    df = df.replace('-', np.nan).dropna()\n",
    "    df = pd.DataFrame(df).astype(float).diff()\n",
    "    df = df.replace(np.nan, 0.)\n",
    "    scaled = scaler.transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled)\n",
    "    pad = np.zeros((max_len, len(scaled_df.columns)))\n",
    "    length = min(max_len, len(scaled_df))\n",
    "    pad[-length:] = scaled_df.to_numpy()[-length:]\n",
    "    env_output = np.round(pad.T, 6)\n",
    "    return env_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbhdoZBuHLt_"
   },
   "source": [
    "- 레이블 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zYCpJLE0tHR",
    "outputId": "d09a3dc9-6a8b-4a66-ac01-257bce8a9eae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5767"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops = []\n",
    "diseases = []\n",
    "risks = []\n",
    "labels_str = []\n",
    "for i in range(len(train_json)):\n",
    "    with open(train_json[i], 'r') as f:\n",
    "        sample = json.load(f)\n",
    "        crop = sample['annotations']['crop']\n",
    "        disease = sample['annotations']['disease']\n",
    "        risk = sample['annotations']['risk']\n",
    "        label=f\"{crop}_{disease}_{risk}\"  \n",
    "        crops.append(crop)\n",
    "        diseases.append(disease)\n",
    "        risks.append(risk)\n",
    "        labels_str.append(label)\n",
    "label2int = sorted(np.unique(labels_str))\n",
    "label2int = {key:value for key,value in zip(label2int, range(len(label2int)))}\n",
    "labels = [label2int[k] for k in labels_str]\n",
    "int2label = {}\n",
    "for key, value in label2int .items():\n",
    "    int2label[value] = key\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcnQlz7dHXr7"
   },
   "source": [
    "- 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMt-PeG-whRy"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Md0jTZaTuZJU",
    "outputId": "5eea15e7-0ad3-482a-8894-0a328484192b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51906/51906 [03:56<00:00, 219.07it/s]\n"
     ]
    }
   ],
   "source": [
    "test_imgs = []\n",
    "for i in tqdm(test_jpg):\n",
    "    test_imgs.append(img_load(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuUUEyrspclU",
    "outputId": "508d46e3-4608-414e-a0dd-4f10728ab3a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51906/51906 [06:52<00:00, 125.73it/s]\n"
     ]
    }
   ],
   "source": [
    "test_envs = []\n",
    "for i in tqdm(test_csv):\n",
    "    test_envs.append(prepro_csv(i, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geMhrrJXw4mV",
    "outputId": "699af488-45b4-48eb-83fe-4846de213d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51906 51906\n"
     ]
    }
   ],
   "source": [
    "print(len(test_imgs), len(test_envs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5JScupoHdfp"
   },
   "source": [
    "#### 데이터 증강 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZS99RB5bpHW"
   },
   "outputs": [],
   "source": [
    "img_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkFZUOTZlMzm"
   },
   "outputs": [],
   "source": [
    "def randRange(a, b):\n",
    "    return np.round(np.random.rand() * (b - a) + a,  2)\n",
    "def rotation(img): \n",
    "    rotated_img = rotate(img, angle=random.choice([-15, 15, 30, -30, 90, -90]))\n",
    "    norm_image = cv2.normalize(rotated_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    rotated_img = norm_image.astype(np.uint8)\n",
    "    return rotated_img\n",
    "def up_down(img):\n",
    "    return np.flipud(img)\n",
    "def left_right(img):\n",
    "    return np.fliplr(img)\n",
    "def noise(img):\n",
    "    noised_img = random_noise(img, var=random.choice([3e-2, 3e-3]))\n",
    "    norm_image = cv2.normalize(noised_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    noised_img = norm_image.astype(np.uint8)\n",
    "    return noised_img\n",
    "def brightness(img):\n",
    "    return img + random.choice([20, 30, 40])\n",
    "def contrast(img):\n",
    "    contrasted_img = img * random.choice([5e-3, 6e-3])\n",
    "    norm_image = cv2.normalize(contrasted_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    contrasted_img = norm_image.astype(np.uint8)\n",
    "    return contrasted_img\n",
    "def blur(img):\n",
    "    return ndimage.uniform_filter(img, size=(random.choice([4, 6]), random.choice([4, 6]), random.choice([1, 1.3])))\n",
    "def random_affine(img):\n",
    "    tform = AffineTransform(scale=(randRange(0.75, 1.3), randRange(0.75, 1.3)),\n",
    "                                                   rotation=randRange(-0.25, 0.25),\n",
    "                                                   shear=randRange(-0.2, 0.2),\n",
    "                                                   translation=(randRange(-img.shape[0]//10, img.shape[0]//10), \n",
    "                                                   randRange(-img.shape[1]//10, img.shape[1]//10)))\n",
    "    affined_img = np.float32(warp(img, tform.inverse, mode='reflect'))\n",
    "    norm_image = cv2.normalize(affined_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    affined_img = norm_image.astype(np.uint8)\n",
    "    return affined_img\n",
    "def random_perspective(img):\n",
    "    region = 1/4\n",
    "    A = np.array([[0, 0], [0, img.shape[0]], [img.shape[1], img.shape[0]], [img.shape[1], 0]])\n",
    "    B = np.array([[int(randRange(0, img.shape[1] * region)), int(randRange(0, img.shape[0] * region))], \n",
    "                            [int(randRange(0, img.shape[1] * region)), int(randRange(img.shape[0] * (1-region), img.shape[0]))], \n",
    "                            [int(randRange(img.shape[1] * (1-region), img.shape[1])), int(randRange(img.shape[0] * (1-region), img.shape[0]))], \n",
    "                            [int(randRange(img.shape[1] * (1-region), img.shape[1])), int(randRange(0, img.shape[0] * region))], \n",
    "                            ])\n",
    "    pt = ProjectiveTransform()\n",
    "    pt.estimate(A, B)\n",
    "    \n",
    "    perspectived_img = np.float32(warp(img, pt, output_shape=img.shape[:2]))\n",
    "    norm_image = cv2.normalize(perspectived_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    perspectived_img = norm_image.astype(np.uint8)\n",
    "    return perspectived_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ggW-IzXlPed"
   },
   "outputs": [],
   "source": [
    "aug_func_list = [rotation, up_down, left_right, noise, brightness, contrast, blur, random_affine, random_perspective]\n",
    "def series_aug(img, aug_func_list):\n",
    "    num_func = random.choice(list(range(2, 7)))\n",
    "    chosen_func = random.sample(aug_func_list, num_func)\n",
    "    random.shuffle(chosen_func)\n",
    "    for func in chosen_func:\n",
    "        img = func(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BOcD1BP1bfi"
   },
   "outputs": [],
   "source": [
    "def skimg_aug(img):\n",
    "    img_augmented = series_aug(img, aug_func_list)\n",
    "    img_augmented_resized = cv2.resize(img_augmented, img_size)\n",
    "    return img_augmented_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuKaKrP0KABu"
   },
   "outputs": [],
   "source": [
    "autoaug = auto_augment_transform(config_str='original', hparams={'translate_const': 100, 'img_mean': (124, 116, 104)})\n",
    "randaug = rand_augment_transform(config_str='rand-m9-mstd0.5', hparams={'translate_const': 117, 'img_mean': (124, 116, 104)})\n",
    "resizecrop = RandomResizedCropAndInterpolation(size=random.choice([300, 400]))\n",
    "timm_func_list = [autoaug, randaug, resizecrop]\n",
    "def timm_aug(img):\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    chosen_func = random.sample(timm_func_list, random.choice([1, 2, 3]))\n",
    "    random.shuffle(chosen_func)\n",
    "    for func in chosen_func:\n",
    "        img = func(img)\n",
    "    img_augmented_resized = cv2.resize(np.array(img), img_size)\n",
    "    return img_augmented_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHo_em6HGS4M"
   },
   "outputs": [],
   "source": [
    "def mixup_aug(idx, beta):\n",
    "    sampled_idx = random.sample(list(train_idx), 1)[0]\n",
    "    img1 = cv2.resize(imgs_oversampled[idx], img_size)\n",
    "    img2 =  cv2.resize(imgs_oversampled[sampled_idx], img_size)\n",
    "    label1 = labels_oversampled[idx]\n",
    "    label2 = labels_oversampled[sampled_idx]\n",
    "    alpha= np.random.beta(beta, beta)\n",
    "    mixup_img = alpha * img1 /255 + (1-alpha) *  img2 /255\n",
    "    mixup_label = alpha * label1 + (1-alpha) * label2\n",
    "    norm_image = cv2.normalize(mixup_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    mixup_img = norm_image.astype(np.uint8)\n",
    "    return mixup_img, np.round(mixup_label, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5hKUI3PTtV1"
   },
   "outputs": [],
   "source": [
    "pre_torch_transformer = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                                                         transforms.RandomPosterize(bits=3, p=0.25),\n",
    "                                                                                         transforms.ColorJitter(brightness=randRange(0.15, 0.3), contrast=randRange(0.15, 0.3), saturation=randRange(0.15, 0.3), hue=randRange(0.15, 0.3)), # 밝기, 대비, 채도, 색조\n",
    "                                                                                         transforms.RandomInvert(p=0.1),\n",
    "                                                                                         transforms.RandomAdjustSharpness(random.choice([2, 4]), p=0.75)\n",
    "                                                                                         ])\n",
    "post_torch_transformer = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                                                         transforms.RandAugment(num_ops=random.randint(1, 4), magnitude=random.randint(1, 4))\n",
    "                                                                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0rl4TWckB1C"
   },
   "outputs": [],
   "source": [
    "def torch_aug_with_bbx(img, idx):\n",
    "    torch_augmented = np.array(pre_torch_transformer(img))\n",
    "    x1, x2, y1, y2 = bbxs_oversampled[idx]\n",
    "    mix_type = random.randint(0, 1)\n",
    "    post_aug = random.randint(0, 1)\n",
    "    if mix_type == 0:\n",
    "        torch_augmented[y1:y2,x1:x2] = img[y1:y2,x1:x2]\n",
    "        if post_aug == 1:\n",
    "            torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "        elif post_aug == 0:\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "    elif mix_type == 1:\n",
    "        img[y1:y2,x1:x2] = torch_augmented[y1:y2,x1:x2]\n",
    "        if post_aug == 1:\n",
    "            img = np.array(post_torch_transformer(img))\n",
    "            return cv2.resize(img, img_size)\n",
    "        elif post_aug == 0:\n",
    "            return cv2.resize(img, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dN682zTkhNwY"
   },
   "outputs": [],
   "source": [
    "def torch_aug_with_part_bbx(img, idx):\n",
    "    torch_augmented = np.array(pre_torch_transformer(img))\n",
    "    part_list = part_oversampled[idx]\n",
    "    mix_type = random.randint(0, 1)\n",
    "    post_aug = random.randint(0, 1)\n",
    "    if len(part_list) == 0:\n",
    "        if post_aug == 1:\n",
    "            torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "        elif post_aug == 0:\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "    else:\n",
    "        if mix_type == 0:\n",
    "            for i in range(len(part_list)):\n",
    "                x1, x2, y1, y2 = part_list[i]\n",
    "                torch_augmented[y1:y2,x1:x2] = img[y1:y2,x1:x2]\n",
    "            if post_aug == 1:\n",
    "                torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
    "                return cv2.resize(torch_augmented, img_size)\n",
    "            elif post_aug == 0:\n",
    "                return cv2.resize(torch_augmented, img_size)\n",
    "        elif mix_type == 1:\n",
    "            for i in range(len(part_list)):\n",
    "                x1, x2, y1, y2 = part_list[i]\n",
    "                img[y1:y2,x1:x2] = torch_augmented[y1:y2,x1:x2]\n",
    "            if post_aug == 1:\n",
    "                img = np.array(post_torch_transformer(img))\n",
    "                return cv2.resize(torch_augmented, img_size)\n",
    "            elif post_aug == 0:\n",
    "                return cv2.resize(img, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWQvvbqU2dlu"
   },
   "outputs": [],
   "source": [
    "def edge_aug(img):\n",
    "    edge_type = random.randint(0, 2)\n",
    "    post_aug = random.randint(0, 1)\n",
    "    if edge_type == 0:\n",
    "        edge = cv2.Canny(img, random.choice([60, 80]), random.choice([60, 80]))\n",
    "        edge = np.stack((edge,)*3, axis=-1)\n",
    "    elif edge_type == 1:\n",
    "        edge = cv2.Sobel(img, -1, 0, 1)\n",
    "    elif edge_type == 2:\n",
    "        edge = cv2.Laplacian(img, -1)\n",
    "    img_edge_added = edge + img\n",
    "    if post_aug == 1:\n",
    "        img_augmented = timm_aug(img_edge_added)\n",
    "    else:\n",
    "        img_augmented = img_edge_added\n",
    "    img_augmented_resized = cv2.resize(img_augmented, img_size)\n",
    "    return img_augmented_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emf01X4VM_v3"
   },
   "outputs": [],
   "source": [
    "def resize_only(img):\n",
    "    img_resized = cv2.resize(img, img_size)\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaHCBETMXnov"
   },
   "outputs": [],
   "source": [
    "def scaling(x, sigma=0.05):\n",
    "    factor = np.random.normal(loc=1., scale=sigma, size=x.shape)\n",
    "    return np.multiply(x, factor)\n",
    "def temporal_aug(envs):\n",
    "    aug = np.round(np.random.rand(), 2)\n",
    "    if aug >= 0.4:\n",
    "        df = pd.DataFrame(envs)\n",
    "        df_nonzero = df.loc[:, (df != 0).any(axis=0)]\n",
    "        df_nonzero_aug = scaling(df_nonzero)\n",
    "        df[df_nonzero_aug.columns] = df_nonzero_aug\n",
    "        return df.values\n",
    "    else:\n",
    "        return envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB1QWrgTHhKG"
   },
   "source": [
    "#### 모델 및  커스텀 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yExSdKLoFEw4"
   },
   "outputs": [],
   "source": [
    "num_class = len(np.unique(labels))\n",
    "rnn_hidden_dim = 512\n",
    "dropout_rate = 0.4\n",
    "cnn_output_dim = 1000\n",
    "rnn_output_dim = 128\n",
    "env_temporal_len = max_len\n",
    "env_feature_len = len(csv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6tYs4uLEqop"
   },
   "outputs": [],
   "source": [
    "class rnn_decoder(nn.Module):\n",
    "    def __init__(self, env_temporal_len, rnn_hidden_dim, rnn_output_dim, env_feature_len, num_class, dropout_rate):\n",
    "        super(rnn_decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(env_temporal_len, rnn_hidden_dim)\n",
    "        self.rnn_fc = nn.Linear(env_feature_len * rnn_hidden_dim, rnn_output_dim)\n",
    "        self.final_layer = nn.Linear(cnn_output_dim + rnn_output_dim, num_class)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, enc_out, dec_inp):\n",
    "        hidden, _ = self.lstm(dec_inp)\n",
    "        hidden = hidden.view(hidden.size(0), -1)\n",
    "        hidden = self.rnn_fc(hidden)\n",
    "        concat = torch.cat([enc_out, hidden], dim=1)\n",
    "        fc_input = concat\n",
    "        output = self.dropout((self.final_layer(fc_input)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6LCRVJyo4Jx"
   },
   "outputs": [],
   "source": [
    "image_model = 'tinynet_a' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLXiu5Fg31Ii"
   },
   "outputs": [],
   "source": [
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, imgs, envs, labels, mode='train'):\n",
    "        self.imgs = imgs\n",
    "        self.envs = envs\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        if self.mode=='train':\n",
    "            aug_type = random.randint(0, 6)\n",
    "            if aug_type in list(range(0, 1)):\n",
    "                img, label = mixup_aug(idx, beta=1)\n",
    "            elif aug_type in list(range(1, 2)):\n",
    "                img = timm_aug(img)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(2, 3)):\n",
    "                img = skimg_aug(img)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(3, 4)):\n",
    "                img = torch_aug_with_bbx(img, idx)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(4, 5)):\n",
    "                img = torch_aug_with_part_bbx(img, idx)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(5, 6)):\n",
    "                img = edge_aug(img)\n",
    "                label = self.labels[idx]\n",
    "            else:\n",
    "                img = resize_only(img)\n",
    "                label = self.labels[idx]\n",
    "            img = transforms.ToTensor()(img)\n",
    "            envs = temporal_aug(self.envs[idx])\n",
    "            return img, envs, label\n",
    "        elif self.mode=='valid':\n",
    "            img = resize_only(img)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            envs = self.envs[idx]\n",
    "            label = self.labels[idx]\n",
    "            return img, envs, label\n",
    "        elif self.mode=='test':\n",
    "            img = resize_only(img)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            envs = self.envs[idx]\n",
    "            return img, envs\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        self.cnn = timm.create_model(image_model, pretrained=True)\n",
    "        self.rnn = rnn_decoder(env_temporal_len, rnn_hidden_dim, rnn_output_dim, env_feature_len, num_class, dropout_rate)\n",
    "\n",
    "    def forward(self, img, env):\n",
    "        x = self.cnn(img)\n",
    "        output = self.rnn(x, env)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcKulZvHLBpI",
    "outputId": "2d17df36-846c-4715-8e56-448efc01522e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda'); device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpOgdhnjLCjV"
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "label_smoothing = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUfxrZ2BLGy0",
    "outputId": "97d5a605-4258-4ab3-cea0-8b762a43b9b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_a.pth\" to /root/.cache/torch/hub/checkpoints/tinynet_a.pth\n"
     ]
    }
   ],
   "source": [
    "model = network().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "gscaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0r2GPqOHr0S"
   },
   "source": [
    "#### 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKWLqnmLu9x-",
    "outputId": "5888f1ed-b715-4aaf-c6bf-b8c68cbae4e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = custom_dataset(test_imgs, test_envs, labels, mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64, pin_memory=True, num_workers=8)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A108ZDjjH1R9"
   },
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxuwG6UWaaG2",
    "outputId": "9f8efb2e-2d9b-4512-e010-169199f934f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_save_path + model_save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bXrNXgu6W64",
    "outputId": "4fb5cba9-f1de-4b3f-fe20-3c988f6d199a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 812/812 [02:23<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "51906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_preds=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        env = torch.tensor(batch[1], dtype=torch.float32, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(img, env)\n",
    "        test_preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "test_preds_converted = [str(int2label[i]) for i in test_preds]\n",
    "print('\\n', len(test_preds_converted), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pGZrXauyV2mp",
    "outputId": "be377b3b-ebcc-4cc0-ddf2-46504594fec4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cace1049-b2e2-4550-bb22-7f0b8c28c1bd\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>0_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>0_00_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cace1049-b2e2-4550-bb22-7f0b8c28c1bd')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cace1049-b2e2-4550-bb22-7f0b8c28c1bd button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cace1049-b2e2-4550-bb22-7f0b8c28c1bd');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   image   label\n",
       "0  10000  0_00_0\n",
       "1  10001  0_00_0\n",
       "2  10002  0_00_0\n",
       "3  10003  0_00_0\n",
       "4  10004  0_00_0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_template = pd.read_csv('data/sample_submission.csv')\n",
    "submission_template.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "g-nLboo09kDP",
    "outputId": "93f1df80-f127-42c5-e03a-af945e68f482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d4afc39c-f438-4b57-bf92-34da95ea686f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>6_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>5_b6_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>4_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>3_00_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>3_b8_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4afc39c-f438-4b57-bf92-34da95ea686f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d4afc39c-f438-4b57-bf92-34da95ea686f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d4afc39c-f438-4b57-bf92-34da95ea686f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   image   label\n",
       "0  10000  6_00_0\n",
       "1  10001  5_b6_1\n",
       "2  10002  4_00_0\n",
       "3  10003  3_00_0\n",
       "4  10004  3_b8_1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = submission_template.copy()\n",
    "submission['label'] = test_preds_converted\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLNdcEOcZSBh"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('data/' + submission_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0wLmgIjwS3a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ztor2_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
