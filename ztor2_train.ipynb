{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpxfkuI5XeV"
      },
      "source": [
        "#### 경로 설정 & 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPAYjuttO-7k",
        "outputId": "dd0fae5b-5ffc-4c8c-e8d8-4c83e4bce943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu75jmTMPABO",
        "outputId": "5b2e273c-92d4-4968-fdb1-df3698e55b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd/content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV2Nvkh_1cMB"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/data/train.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rszjq2gk1Pux",
        "outputId": "2d5b74bc-d38b-4ad4-a267-e913dcd4347c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l75gjNw0dEf"
      },
      "outputs": [],
      "source": [
        "import warnings; warnings.filterwarnings('ignore')\n",
        "import random\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from skimage.transform import warp, rotate, AffineTransform, ProjectiveTransform\n",
        "from skimage.util import random_noise\n",
        "from scipy import ndimage\n",
        "\n",
        "import timm\n",
        "from timm.data.auto_augment import auto_augment_transform\n",
        "from timm.data.auto_augment import rand_augment_transform\n",
        "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7H100yJ1iTr"
      },
      "outputs": [],
      "source": [
        "train_csv = sorted(glob('train/*/*.csv'))\n",
        "train_jpg = sorted(glob('train/*/*.jpg'))\n",
        "train_json = sorted(glob('train/*/*.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUHhP_gDIJFs"
      },
      "source": [
        "#### 데이터 전처리 & 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiSRUlExHQt4"
      },
      "source": [
        "- 환경 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY4ngEfNXyxY"
      },
      "outputs": [],
      "source": [
        "max_len = 600\n",
        "csv_features = ['내부 온도 1 평균', '내부 습도 1 평균', '내부 이슬점 평균']\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfzWFkEc98fo",
        "outputId": "0f7aa457-401b-4cbb-cedd-6910d7b8af45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5766/5766 [01:39<00:00, 57.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(num_row, num_feat): (1772360, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "first_env = pd.read_csv(train_csv[0])[csv_features]\n",
        "first_env = first_env.replace('-',np.nan)\n",
        "first_env = pd.DataFrame(imputer.fit_transform(first_env))\n",
        "env_concat = first_env.astype(float).diff().iloc[1:].values\n",
        "for csv_path in tqdm(train_csv[1:]):\n",
        "    tmp = pd.read_csv(csv_path)[csv_features]\n",
        "    tmp = tmp.replace('-', np.nan)\n",
        "    tmp = pd.DataFrame(imputer.fit_transform(tmp))\n",
        "    tmp = tmp.astype(float).diff().replace(np.nan, 0.).values\n",
        "    if len(tmp) <= 1:\n",
        "        continue\n",
        "    env_concat = np.vstack((env_concat, tmp[1:]))\n",
        "print('\\n(num_row, num_feat): ', env_concat.shape, sep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOCglEs7GJSo"
      },
      "outputs": [],
      "source": [
        "scaler = RobustScaler().fit(env_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQh1ip4KInzH"
      },
      "outputs": [],
      "source": [
        "def prepro_csv(csv_file, max_len=200):\n",
        "    df = pd.read_csv(csv_file)[csv_features]\n",
        "    df = df.replace('-', np.nan).dropna()\n",
        "    df = pd.DataFrame(df).astype(float).diff()\n",
        "    df = df.replace(np.nan, 0.)\n",
        "    scaled = scaler.transform(df)\n",
        "    scaled_df = pd.DataFrame(scaled)\n",
        "    pad = np.zeros((max_len, len(scaled_df.columns)))\n",
        "    length = min(max_len, len(scaled_df))\n",
        "    pad[-length:] = scaled_df.to_numpy()[-length:]\n",
        "    env_output = np.round(pad.T, 6)\n",
        "    return env_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbhdoZBuHLt_"
      },
      "source": [
        "- 레이블 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zYCpJLE0tHR",
        "outputId": "735d0396-fe81-4fc3-edd4-6d8f44f37029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5767"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "crops = []\n",
        "diseases = []\n",
        "risks = []\n",
        "labels_str = []\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "        crop = sample['annotations']['crop']\n",
        "        disease = sample['annotations']['disease']\n",
        "        risk = sample['annotations']['risk']\n",
        "        label=f\"{crop}_{disease}_{risk}\"  \n",
        "        crops.append(crop)\n",
        "        diseases.append(disease)\n",
        "        risks.append(risk)\n",
        "        labels_str.append(label)\n",
        "label2int = sorted(np.unique(labels_str))\n",
        "label2int = {key:value for key,value in zip(label2int, range(len(label2int)))}\n",
        "labels = [label2int[k] for k in labels_str]\n",
        "int2label = {}\n",
        "for key, value in label2int .items():\n",
        "    int2label[value] = key\n",
        "len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcnQlz7dHXr7"
      },
      "source": [
        "- 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMt-PeG-whRy"
      },
      "outputs": [],
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HimDLnjWFxqU",
        "outputId": "e3e16e82-1887-4435-e38a-4b7b17affb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5767/5767 [00:32<00:00, 179.59it/s]\n"
          ]
        }
      ],
      "source": [
        "imgs = []\n",
        "for i in tqdm(train_jpg):\n",
        "    imgs.append(img_load(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "See5lv-Pyd3y",
        "outputId": "bc2d3015-2373-4f5d-aabb-6b00f12f8814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5767/5767 [00:55<00:00, 103.06it/s]\n"
          ]
        }
      ],
      "source": [
        "envs = []\n",
        "for i in tqdm(train_csv):\n",
        "    envs.append(prepro_csv(i, max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysPIEd5Sgmba"
      },
      "outputs": [],
      "source": [
        "bbxs = []\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        tmp = json.load(f)\n",
        "    X = int(tmp['annotations']['bbox'][0]['x'])\n",
        "    H = int(tmp['annotations']['bbox'][0]['h'])\n",
        "    Y = int(tmp['annotations']['bbox'][0]['y'])\n",
        "    W = int(tmp['annotations']['bbox'][0]['w'])\n",
        "    bbxs.append([X, X+W, Y, Y+H])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geAlmDeaaxAr"
      },
      "outputs": [],
      "source": [
        "part = []\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        tmp = json.load(f)\n",
        "    num_part = len(tmp['annotations']['part'])\n",
        "    if num_part == 0:\n",
        "        part.append([])\n",
        "    else:\n",
        "        sub_list = []\n",
        "        for i in range(num_part):\n",
        "            X = int(tmp['annotations']['part'][i]['x'])\n",
        "            H = int(tmp['annotations']['part'][i]['h'])\n",
        "            Y = int(tmp['annotations']['part'][i]['y'])\n",
        "            W = int(tmp['annotations']['part'][i]['w'])\n",
        "            sub_list.append([X, X+W, Y, Y+H])\n",
        "        part.append(sub_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvoxos4NgkIw",
        "outputId": "3cf1a49f-81bd-4af4-834c-b29c6e8dd75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5767 5767 5767 5767 5767\n"
          ]
        }
      ],
      "source": [
        "print(len(imgs), len(envs), len(labels), len(bbxs), len(part))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKxjH-c3GEDW"
      },
      "source": [
        "#### 데이터 오버샘플링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A-XaM34_5uk",
        "outputId": "bbbc3eef-168d-49e4-ee3d-2cdd74c750dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d25005e7-f41a-438d-8d6f-7c897a64ae23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d25005e7-f41a-438d-8d6f-7c897a64ae23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d25005e7-f41a-438d-8d6f-7c897a64ae23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d25005e7-f41a-438d-8d6f-7c897a64ae23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Label frequency\n",
              "0               810\n",
              "1               143\n",
              "2               189\n",
              "3              1177\n",
              "4               154\n",
              "5               111\n",
              "6                42\n",
              "7               166\n",
              "8               142\n",
              "9               156\n",
              "10              153\n",
              "11              917\n",
              "12               69\n",
              "13               99\n",
              "14              148\n",
              "15              159\n",
              "16              157\n",
              "17              828\n",
              "18               40\n",
              "19               12\n",
              "20               13\n",
              "21               29\n",
              "22               18\n",
              "23               14\n",
              "24               21"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq = {i:labels.count(i) for i in set(labels)}\n",
        "freqdf = pd.DataFrame(freq.values(), columns=['Label frequency']); freqdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWmUHOd4AVlr",
        "outputId": "361dc3da-abd3-4c6a-90aa-244fd4ceb9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19 20 22 23]\n",
            "[ 6 18 21 24]\n",
            "[12]\n"
          ]
        }
      ],
      "source": [
        "imbalance_label_1 = np.unique([i for i in labels if freq[i] < 20])\n",
        "imbalance_label_2 = np.unique([i for i in labels if freq[i] >= 20 and freq[i] <= 42])\n",
        "imbalance_label_3 = np.unique([i for i in labels if freq[i] > 42 and freq[i] < 70])\n",
        "print(imbalance_label_1, '\\n', imbalance_label_2, '\\n', imbalance_label_3, sep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfhRuhDTAwr8"
      },
      "outputs": [],
      "source": [
        "oversample_num_1 = 12\n",
        "oversample_num_2 = 5\n",
        "oversample_num_3 = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzhJvaBsyFTB"
      },
      "outputs": [],
      "source": [
        "imgs_oversampled = imgs.copy()\n",
        "envs_oversampled = envs.copy()\n",
        "labels_oversampled = labels.copy()\n",
        "bbxs_oversampled = bbxs.copy()\n",
        "part_oversampled = part.copy()\n",
        "labels_str_oversampled = labels_str.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJYtLFECA084",
        "outputId": "4b14fefa-0c62-4cf5-8718-7500263bd4be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5767/5767 [00:00<00:00, 102153.21it/s]\n"
          ]
        }
      ],
      "source": [
        "for idx, label in enumerate(tqdm(labels)):\n",
        "    if label in imbalance_label_1:\n",
        "        for i in range(oversample_num_1):\n",
        "            imgs_oversampled.append(imgs[idx])\n",
        "            envs_oversampled.append(envs[idx])\n",
        "            labels_oversampled.append(label)\n",
        "            labels_str_oversampled.append(labels_str[idx])\n",
        "            bbxs_oversampled.append(bbxs[idx])\n",
        "            part_oversampled.append(part[idx])\n",
        "    elif label in imbalance_label_2:\n",
        "        for i in range(oversample_num_2):\n",
        "            imgs_oversampled.append(imgs[idx])\n",
        "            envs_oversampled.append(envs[idx])\n",
        "            labels_oversampled.append(label)\n",
        "            labels_str_oversampled.append(labels_str[idx])\n",
        "            bbxs_oversampled.append(bbxs[idx])\n",
        "            part_oversampled.append(part[idx])\n",
        "    elif label in imbalance_label_3:\n",
        "        for i in range(oversample_num_3):\n",
        "            imgs_oversampled.append(imgs[idx])\n",
        "            envs_oversampled.append(envs[idx])\n",
        "            labels_oversampled.append(label)\n",
        "            labels_str_oversampled.append(labels_str[idx])\n",
        "            bbxs_oversampled.append(bbxs[idx])\n",
        "            part_oversampled.append(part[idx])\n",
        "    else:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI6TBtHhu_kL",
        "outputId": "2db7cccd-962f-4185-a0b0-3f9b1906e8d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-55659e06-5877-4d84-aede-cc64ba4ba592\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55659e06-5877-4d84-aede-cc64ba4ba592')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55659e06-5877-4d84-aede-cc64ba4ba592 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55659e06-5877-4d84-aede-cc64ba4ba592');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Label frequency\n",
              "0               810\n",
              "1               143\n",
              "2               189\n",
              "3              1177\n",
              "4               154\n",
              "5               111\n",
              "6               252\n",
              "7               166\n",
              "8               142\n",
              "9               156\n",
              "10              153\n",
              "11              917\n",
              "12              207\n",
              "13               99\n",
              "14              148\n",
              "15              159\n",
              "16              157\n",
              "17              828\n",
              "18              240\n",
              "19              156\n",
              "20              169\n",
              "21              174\n",
              "22              234\n",
              "23              182\n",
              "24              126"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_oversampled = {i:labels_oversampled.count(i) for i in set(labels_oversampled)}\n",
        "freqdf_oversampled = pd.DataFrame(freq_oversampled.values(), columns=['Label frequency']); freqdf_oversampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kAJXiueBeFV",
        "outputId": "6b30e737-59ec-4366-a502-f57ec0b7d2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7249 7249 7249 7249 7249 7249\n"
          ]
        }
      ],
      "source": [
        "print(len(imgs_oversampled), len(envs_oversampled), len(labels_oversampled), len(bbxs_oversampled), len(part_oversampled), len(labels_str_oversampled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5JScupoHdfp"
      },
      "source": [
        "#### 데이터 증강 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZS99RB5bpHW"
      },
      "outputs": [],
      "source": [
        "img_size = (512, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkFZUOTZlMzm"
      },
      "outputs": [],
      "source": [
        "def randRange(a, b):\n",
        "    return np.round(np.random.rand() * (b - a) + a,  2)\n",
        "def rotation(img): \n",
        "    rotated_img = rotate(img, angle=random.choice([-15, 15, 30, -30, 90, -90]))\n",
        "    norm_image = cv2.normalize(rotated_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
        "    rotated_img = norm_image.astype(np.uint8)\n",
        "    return rotated_img\n",
        "def up_down(img):\n",
        "    return np.flipud(img)\n",
        "def left_right(img):\n",
        "    return np.fliplr(img)\n",
        "def noise(img):\n",
        "    noised_img = random_noise(img, var=random.choice([3e-2, 3e-3]))\n",
        "    norm_image = cv2.normalize(noised_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
        "    noised_img = norm_image.astype(np.uint8)\n",
        "    return noised_img\n",
        "def brightness(img):\n",
        "    return img + random.choice([20, 30, 40])\n",
        "def contrast(img):\n",
        "    contrasted_img = img * random.choice([5e-3, 6e-3])\n",
        "    norm_image = cv2.normalize(contrasted_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
        "    contrasted_img = norm_image.astype(np.uint8)\n",
        "    return contrasted_img\n",
        "def blur(img):\n",
        "    return ndimage.uniform_filter(img, size=(random.choice([4, 6]), random.choice([4, 6]), random.choice([1, 1.3])))\n",
        "def random_affine(img):\n",
        "    tform = AffineTransform(scale=(randRange(0.75, 1.3), randRange(0.75, 1.3)),\n",
        "                                                   rotation=randRange(-0.25, 0.25),\n",
        "                                                   shear=randRange(-0.2, 0.2),\n",
        "                                                   translation=(randRange(-img.shape[0]//10, img.shape[0]//10), \n",
        "                                                   randRange(-img.shape[1]//10, img.shape[1]//10)))\n",
        "    affined_img = np.float32(warp(img, tform.inverse, mode='reflect'))\n",
        "    norm_image = cv2.normalize(affined_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
        "    affined_img = norm_image.astype(np.uint8)\n",
        "    return affined_img\n",
        "def random_perspective(img):\n",
        "    region = 1/4\n",
        "    A = np.array([[0, 0], [0, img.shape[0]], [img.shape[1], img.shape[0]], [img.shape[1], 0]])\n",
        "    B = np.array([[int(randRange(0, img.shape[1] * region)), int(randRange(0, img.shape[0] * region))], \n",
        "                            [int(randRange(0, img.shape[1] * region)), int(randRange(img.shape[0] * (1-region), img.shape[0]))], \n",
        "                            [int(randRange(img.shape[1] * (1-region), img.shape[1])), int(randRange(img.shape[0] * (1-region), img.shape[0]))], \n",
        "                            [int(randRange(img.shape[1] * (1-region), img.shape[1])), int(randRange(0, img.shape[0] * region))], \n",
        "                            ])\n",
        "    pt = ProjectiveTransform()\n",
        "    pt.estimate(A, B)\n",
        "    \n",
        "    perspectived_img = np.float32(warp(img, pt, output_shape=img.shape[:2]))\n",
        "    norm_image = cv2.normalize(perspectived_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
        "    perspectived_img = norm_image.astype(np.uint8)\n",
        "    return perspectived_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ggW-IzXlPed"
      },
      "outputs": [],
      "source": [
        "aug_func_list = [rotation, up_down, left_right, noise, brightness, contrast, blur, random_affine, random_perspective]\n",
        "def series_aug(img, aug_func_list):\n",
        "    num_func = random.choice(list(range(2, 7)))\n",
        "    chosen_func = random.sample(aug_func_list, num_func)\n",
        "    random.shuffle(chosen_func)\n",
        "    for func in chosen_func:\n",
        "        img = func(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BOcD1BP1bfi"
      },
      "outputs": [],
      "source": [
        "def skimg_aug(img):\n",
        "    img_augmented = series_aug(img, aug_func_list)\n",
        "    img_augmented_resized = cv2.resize(img_augmented, img_size)\n",
        "    return img_augmented_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuKaKrP0KABu"
      },
      "outputs": [],
      "source": [
        "autoaug = auto_augment_transform(config_str='original', hparams={'translate_const': 100, 'img_mean': (124, 116, 104)})\n",
        "randaug = rand_augment_transform(config_str='rand-m9-mstd0.5', hparams={'translate_const': 117, 'img_mean': (124, 116, 104)})\n",
        "resizecrop = RandomResizedCropAndInterpolation(size=random.choice([300, 400]))\n",
        "timm_func_list = [autoaug, randaug, resizecrop]\n",
        "def timm_aug(img):\n",
        "    img = Image.fromarray(np.uint8(img))\n",
        "    chosen_func = random.sample(timm_func_list, random.choice([1, 2, 3]))\n",
        "    random.shuffle(chosen_func)\n",
        "    for func in chosen_func:\n",
        "        img = func(img)\n",
        "    img_augmented_resized = cv2.resize(np.array(img), img_size)\n",
        "    return img_augmented_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHo_em6HGS4M"
      },
      "outputs": [],
      "source": [
        "def mixup_aug(idx, beta):\n",
        "    sampled_idx = random.sample(list(train_idx), 1)[0]\n",
        "    img1 = cv2.resize(imgs_oversampled[idx], img_size)\n",
        "    img2 =  cv2.resize(imgs_oversampled[sampled_idx], img_size)\n",
        "    label1 = labels_oversampled[idx]\n",
        "    label2 = labels_oversampled[sampled_idx]\n",
        "    alpha= np.random.beta(beta, beta)\n",
        "    mixup_img = alpha * img1 /255 + (1-alpha) *  img2 /255\n",
        "    mixup_label = alpha * label1 + (1-alpha) * label2\n",
        "    norm_image = cv2.normalize(mixup_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
        "    mixup_img = norm_image.astype(np.uint8)\n",
        "    return mixup_img, np.round(mixup_label, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5hKUI3PTtV1"
      },
      "outputs": [],
      "source": [
        "pre_torch_transformer = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                                                         transforms.RandomPosterize(bits=3, p=0.25),\n",
        "                                                                                         transforms.ColorJitter(brightness=randRange(0.15, 0.3), contrast=randRange(0.15, 0.3), saturation=randRange(0.15, 0.3), hue=randRange(0.15, 0.3)), # 밝기, 대비, 채도, 색조\n",
        "                                                                                         transforms.RandomInvert(p=0.1),\n",
        "                                                                                         transforms.RandomAdjustSharpness(random.choice([2, 4]), p=0.75)\n",
        "                                                                                         ])\n",
        "post_torch_transformer = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                                                         transforms.RandAugment(num_ops=random.randint(1, 4), magnitude=random.randint(1, 4))\n",
        "                                                                                         ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0rl4TWckB1C"
      },
      "outputs": [],
      "source": [
        "def torch_aug_with_bbx(img, idx):\n",
        "    torch_augmented = np.array(pre_torch_transformer(img))\n",
        "    x1, x2, y1, y2 = bbxs_oversampled[idx]\n",
        "    mix_type = random.randint(0, 1)\n",
        "    post_aug = random.randint(0, 1)\n",
        "    if mix_type == 0:\n",
        "        torch_augmented[y1:y2,x1:x2] = img[y1:y2,x1:x2]\n",
        "        if post_aug == 1:\n",
        "            torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
        "            return cv2.resize(torch_augmented, img_size)\n",
        "        elif post_aug == 0:\n",
        "            return cv2.resize(torch_augmented, img_size)\n",
        "    elif mix_type == 1:\n",
        "        img[y1:y2,x1:x2] = torch_augmented[y1:y2,x1:x2]\n",
        "        if post_aug == 1:\n",
        "            img = np.array(post_torch_transformer(img))\n",
        "            return cv2.resize(img, img_size)\n",
        "        elif post_aug == 0:\n",
        "            return cv2.resize(img, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN682zTkhNwY"
      },
      "outputs": [],
      "source": [
        "def torch_aug_with_part_bbx(img, idx):\n",
        "    torch_augmented = np.array(pre_torch_transformer(img))\n",
        "    part_list = part_oversampled[idx]\n",
        "    mix_type = random.randint(0, 1)\n",
        "    post_aug = random.randint(0, 1)\n",
        "    if len(part_list) == 0:\n",
        "        if post_aug == 1:\n",
        "            torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
        "            return cv2.resize(torch_augmented, img_size)\n",
        "        elif post_aug == 0:\n",
        "            return cv2.resize(torch_augmented, img_size)\n",
        "    else:\n",
        "        if mix_type == 0:\n",
        "            for i in range(len(part_list)):\n",
        "                x1, x2, y1, y2 = part_list[i]\n",
        "                torch_augmented[y1:y2,x1:x2] = img[y1:y2,x1:x2]\n",
        "            if post_aug == 1:\n",
        "                torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
        "                return cv2.resize(torch_augmented, img_size)\n",
        "            elif post_aug == 0:\n",
        "                return cv2.resize(torch_augmented, img_size)\n",
        "        elif mix_type == 1:\n",
        "            for i in range(len(part_list)):\n",
        "                x1, x2, y1, y2 = part_list[i]\n",
        "                img[y1:y2,x1:x2] = torch_augmented[y1:y2,x1:x2]\n",
        "                if post_aug == 1:\n",
        "                    img = np.array(post_torch_transformer(img))\n",
        "                    return cv2.resize(torch_augmented, img_size)\n",
        "                elif post_aug == 0:\n",
        "                    return cv2.resize(img, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWQvvbqU2dlu"
      },
      "outputs": [],
      "source": [
        "def edge_aug(img):\n",
        "    edge_type = random.randint(0, 2)\n",
        "    post_aug = random.randint(0, 1)\n",
        "    if edge_type == 0:\n",
        "        edge = cv2.Canny(img, random.choice([60, 80]), random.choice([60, 80]))\n",
        "        edge = np.stack((edge,)*3, axis=-1)\n",
        "    elif edge_type == 1:\n",
        "        edge = cv2.Sobel(img, -1, 0, 1)\n",
        "    elif edge_type == 2:\n",
        "        edge = cv2.Laplacian(img, -1)\n",
        "    img_edge_added = edge + img\n",
        "    if post_aug == 1:\n",
        "        img_augmented = timm_aug(img_edge_added)\n",
        "    else:\n",
        "        img_augmented = img_edge_added\n",
        "    img_augmented_resized = cv2.resize(img_augmented, img_size)\n",
        "    return img_augmented_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emf01X4VM_v3"
      },
      "outputs": [],
      "source": [
        "def resize_only(img):\n",
        "    img_resized = cv2.resize(img, img_size)\n",
        "    return img_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaHCBETMXnov"
      },
      "outputs": [],
      "source": [
        "def scaling(x, sigma=0.05):\n",
        "    factor = np.random.normal(loc=1., scale=sigma, size=x.shape)\n",
        "    return np.multiply(x, factor)\n",
        "def temporal_aug(envs):\n",
        "    aug = np.round(np.random.rand(), 2)\n",
        "    if aug >= 0.4:\n",
        "        df = pd.DataFrame(envs)\n",
        "        df_nonzero = df.loc[:, (df != 0).any(axis=0)]\n",
        "        df_nonzero_aug = scaling(df_nonzero)\n",
        "        df[df_nonzero_aug.columns] = df_nonzero_aug\n",
        "        return df.values\n",
        "    else:\n",
        "        return envs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB1QWrgTHhKG"
      },
      "source": [
        "#### 모델 및  커스텀 데이터셋 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yExSdKLoFEw4"
      },
      "outputs": [],
      "source": [
        "num_class = len(np.unique(labels))\n",
        "rnn_hidden_dim = 512\n",
        "dropout_rate = 0.4\n",
        "cnn_output_dim = 1000\n",
        "rnn_output_dim = 128\n",
        "env_temporal_len = max_len\n",
        "env_feature_len = len(csv_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6tYs4uLEqop"
      },
      "outputs": [],
      "source": [
        "class rnn_decoder(nn.Module):\n",
        "    def __init__(self, env_temporal_len, rnn_hidden_dim, rnn_output_dim, env_feature_len, num_class, dropout_rate):\n",
        "        super(rnn_decoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(env_temporal_len, rnn_hidden_dim)\n",
        "        self.rnn_fc = nn.Linear(env_feature_len * rnn_hidden_dim, rnn_output_dim)\n",
        "        self.final_layer = nn.Linear(cnn_output_dim + rnn_output_dim, num_class)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, enc_out, dec_inp):\n",
        "        hidden, _ = self.lstm(dec_inp)\n",
        "        hidden = hidden.view(hidden.size(0), -1)\n",
        "        hidden = self.rnn_fc(hidden)\n",
        "        concat = torch.cat([enc_out, hidden], dim=1)\n",
        "        fc_input = concat\n",
        "        output = self.dropout((self.final_layer(fc_input)))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6LCRVJyo4Jx"
      },
      "outputs": [],
      "source": [
        "image_model = 'tinynet_a' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLXiu5Fg31Ii"
      },
      "outputs": [],
      "source": [
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, imgs, envs, labels, mode='train'):\n",
        "        self.imgs = imgs\n",
        "        self.envs = envs\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[idx]\n",
        "        if self.mode=='train':\n",
        "            aug_type = random.randint(0, 6)\n",
        "            if aug_type in list(range(0, 1)):\n",
        "                img, label = mixup_aug(idx, beta=1)\n",
        "            elif aug_type in list(range(1, 2)):\n",
        "                img = timm_aug(img)\n",
        "                label = self.labels[idx]\n",
        "            elif aug_type in list(range(2, 3)):\n",
        "                img = skimg_aug(img)\n",
        "                label = self.labels[idx]\n",
        "            elif aug_type in list(range(3, 4)):\n",
        "                img = torch_aug_with_bbx(img, idx)\n",
        "                label = self.labels[idx]\n",
        "            elif aug_type in list(range(4, 5)):\n",
        "                img = torch_aug_with_part_bbx(img, idx)\n",
        "                label = self.labels[idx]\n",
        "            elif aug_type in list(range(5, 6)):\n",
        "                img = edge_aug(img)\n",
        "                label = self.labels[idx]\n",
        "            else:\n",
        "                img = resize_only(img)\n",
        "                label = self.labels[idx]\n",
        "            img = transforms.ToTensor()(img)\n",
        "            envs = temporal_aug(self.envs[idx])\n",
        "            return img, envs, label\n",
        "        elif self.mode=='valid':\n",
        "            img = resize_only(img)\n",
        "            img = transforms.ToTensor()(img)\n",
        "            envs = self.envs[idx]\n",
        "            label = self.labels[idx]\n",
        "            return img, envs, label\n",
        "        elif self.mode=='test':\n",
        "            img = resize_only(img)\n",
        "            img = transforms.ToTensor()(img)\n",
        "            envs = self.envs[idx]\n",
        "            return img, envs\n",
        "\n",
        "class network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(network, self).__init__()\n",
        "        self.cnn = timm.create_model(image_model, pretrained=True)\n",
        "        self.rnn = rnn_decoder(env_temporal_len, rnn_hidden_dim, rnn_output_dim, env_feature_len, num_class, dropout_rate)\n",
        "\n",
        "    def forward(self, img, env):\n",
        "        x = self.cnn(img)\n",
        "        output = self.rnn(x, env)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcKulZvHLBpI",
        "outputId": "afa8a104-353e-4feb-9042-b5826bbdfa4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda'); device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpOgdhnjLCjV"
      },
      "outputs": [],
      "source": [
        "learning_rate = 5e-5\n",
        "label_smoothing = 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUfxrZ2BLGy0",
        "outputId": "fa348387-b6d8-4bd7-f3cf-f7c985454978"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/huawei-noah/CV-Backbones/releases/download/v1.2.0/tinynet_a.pth\" to /root/.cache/torch/hub/checkpoints/tinynet_a.pth\n"
          ]
        }
      ],
      "source": [
        "model = network().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "gscaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz8FBv7jNlzq"
      },
      "outputs": [],
      "source": [
        "def accuracy_function(real, pred):\n",
        "    score = f1_score(real, pred, average='macro')\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0r2GPqOHr0S"
      },
      "source": [
        "#### 데이터로더"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjKkkpMaLQWb",
        "outputId": "0186831a-9d8e-4653-8a62-03ab5a046ca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train: 6213 num_val; 1036\n",
            "ratio_train: 0.86 ratio_val: 0.14\n"
          ]
        }
      ],
      "source": [
        "n_splits = 7\n",
        "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=41)\n",
        "folds = [(train_idx, valid_idx) for train_idx, valid_idx in kf.split(imgs_oversampled, labels_oversampled)]\n",
        "train_idx, valid_idx = folds[0]\n",
        "train_imgs = list(map(imgs_oversampled.__getitem__, train_idx))\n",
        "train_envs = list(map(envs_oversampled.__getitem__, train_idx))\n",
        "train_labels = list(map(labels_oversampled.__getitem__, train_idx))\n",
        "train_labels_str = list(map(labels_str_oversampled.__getitem__, train_idx))\n",
        "val_imgs = list(map(imgs_oversampled.__getitem__, valid_idx))\n",
        "val_envs = list(map(envs_oversampled.__getitem__, valid_idx))\n",
        "val_labels = list(map(labels_oversampled.__getitem__, valid_idx))\n",
        "print('num_train: {} num_val; {}'.format(len(train_idx), len(valid_idx)))\n",
        "print('ratio_train: {} ratio_val: {}'.format(np.round(len(train_idx)/len(imgs_oversampled), 2), np.round(len(valid_idx)/len(imgs_oversampled), 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce4yynwULQPV"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ulbcgOS6BVG"
      },
      "outputs": [],
      "source": [
        "train_dataset = custom_dataset(train_imgs, train_envs, train_labels, mode='train')\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=8)\n",
        "\n",
        "valid_dataset = custom_dataset(val_imgs, val_envs, val_labels, mode='valid')\n",
        "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size, pin_memory=True, num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0O4HK-iHxit"
      },
      "source": [
        "#### 학습 & 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QSYL29Eq6J2"
      },
      "outputs": [],
      "source": [
        "epochs = 80\n",
        "model_save_path =  './drive/MyDrive/data/'\n",
        "model_save_name = 'model_v20_0205_best_f1.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoArz69S6IZ1",
        "outputId": "5996fe96-09c5-488a-d9e6-853308d89e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1/85                time : 95s/7962s\n",
            "TRAIN loss : 3.24083    f1: 0.12871\n",
            "VALID loss : 3.21496    f1: 0.49404    best: 0.49404\n",
            "epoch : 2/85                time : 93s/7713s\n",
            "TRAIN loss : 3.21836    f1: 0.26519\n",
            "VALID loss : 3.21212    f1: 0.70034    best: 0.70034\n",
            "epoch : 3/85                time : 96s/7910s\n",
            "TRAIN loss : 3.21604    f1: 0.35018\n",
            "VALID loss : 3.21088    f1: 0.73736    best: 0.73736\n",
            "epoch : 4/85                time : 95s/7725s\n",
            "TRAIN loss : 3.21487    f1: 0.39575\n",
            "VALID loss : 3.21005    f1: 0.80017    best: 0.80017\n",
            "epoch : 5/85                time : 93s/7479s\n",
            "TRAIN loss : 3.21439    f1: 0.40091\n",
            "VALID loss : 3.20969    f1: 0.84713    best: 0.84713\n",
            "epoch : 6/85                time : 97s/7628s\n",
            "TRAIN loss : 3.21419    f1: 0.41828\n",
            "VALID loss : 3.20916    f1: 0.86130    best: 0.86130\n",
            "epoch : 7/85                time : 96s/7503s\n",
            "TRAIN loss : 3.21362    f1: 0.44024\n",
            "VALID loss : 3.20904    f1: 0.88311    best: 0.88311\n",
            "epoch : 8/85                time : 95s/7290s\n",
            "TRAIN loss : 3.21339    f1: 0.45710\n",
            "VALID loss : 3.20863    f1: 0.88707    best: 0.88707\n",
            "epoch : 9/85                time : 96s/7298s\n",
            "TRAIN loss : 3.21313    f1: 0.47376\n",
            "VALID loss : 3.20816    f1: 0.90388    best: 0.90388\n",
            "epoch : 10/85                time : 96s/7194s\n",
            "TRAIN loss : 3.21299    f1: 0.46877\n",
            "VALID loss : 3.20816    f1: 0.89336    best: 0.90388\n",
            "epoch : 11/85                time : 94s/6975s\n",
            "TRAIN loss : 3.21259    f1: 0.47551\n",
            "VALID loss : 3.20774    f1: 0.90001    best: 0.90388\n",
            "epoch : 12/85                time : 96s/6981s\n",
            "TRAIN loss : 3.21278    f1: 0.45985\n",
            "VALID loss : 3.20780    f1: 0.90582    best: 0.90582\n",
            "epoch : 13/85                time : 95s/6852s\n",
            "TRAIN loss : 3.21274    f1: 0.46394\n",
            "VALID loss : 3.20780    f1: 0.93380    best: 0.93380\n",
            "epoch : 14/85                time : 95s/6739s\n",
            "TRAIN loss : 3.21240    f1: 0.47455\n",
            "VALID loss : 3.20780    f1: 0.92556    best: 0.93380\n",
            "epoch : 15/85                time : 95s/6681s\n",
            "TRAIN loss : 3.21262    f1: 0.46251\n",
            "VALID loss : 3.20739    f1: 0.90442    best: 0.93380\n",
            "epoch : 16/85                time : 95s/6553s\n",
            "TRAIN loss : 3.21202    f1: 0.49603\n",
            "VALID loss : 3.20739    f1: 0.91051    best: 0.93380\n",
            "epoch : 17/85                time : 96s/6527s\n",
            "TRAIN loss : 3.21211    f1: 0.49068\n",
            "VALID loss : 3.20745    f1: 0.92836    best: 0.93380\n",
            "epoch : 18/85                time : 92s/6181s\n",
            "TRAIN loss : 3.21214    f1: 0.47906\n",
            "VALID loss : 3.20774    f1: 0.93242    best: 0.93380\n",
            "epoch : 19/85                time : 95s/6280s\n",
            "TRAIN loss : 3.21205    f1: 0.49049\n",
            "VALID loss : 3.20745    f1: 0.93541    best: 0.93541\n",
            "epoch : 20/85                time : 95s/6161s\n",
            "TRAIN loss : 3.21212    f1: 0.48298\n",
            "VALID loss : 3.20762    f1: 0.93443    best: 0.93541\n",
            "epoch : 21/85                time : 95s/6056s\n",
            "TRAIN loss : 3.21208    f1: 0.48809\n",
            "VALID loss : 3.20733    f1: 0.94157    best: 0.94157\n",
            "epoch : 22/85                time : 95s/5961s\n",
            "TRAIN loss : 3.21186    f1: 0.49369\n",
            "VALID loss : 3.20721    f1: 0.93986    best: 0.94157\n",
            "epoch : 23/85                time : 97s/6044s\n",
            "TRAIN loss : 3.21176    f1: 0.50269\n",
            "VALID loss : 3.20691    f1: 0.94886    best: 0.94886\n",
            "epoch : 24/85                time : 95s/5769s\n",
            "TRAIN loss : 3.21187    f1: 0.48216\n",
            "VALID loss : 3.20721    f1: 0.95156    best: 0.95156\n",
            "epoch : 25/85                time : 95s/5707s\n",
            "TRAIN loss : 3.21178    f1: 0.49820\n",
            "VALID loss : 3.20739    f1: 0.94770    best: 0.95156\n",
            "epoch : 26/85                time : 96s/5661s\n",
            "TRAIN loss : 3.21179    f1: 0.49116\n",
            "VALID loss : 3.20685    f1: 0.95338    best: 0.95338\n",
            "epoch : 27/85                time : 96s/5578s\n",
            "TRAIN loss : 3.21198    f1: 0.48283\n",
            "VALID loss : 3.20721    f1: 0.94841    best: 0.95338\n",
            "epoch : 28/85                time : 96s/5444s\n",
            "TRAIN loss : 3.21188    f1: 0.47591\n",
            "VALID loss : 3.20691    f1: 0.95103    best: 0.95338\n",
            "epoch : 29/85                time : 95s/5318s\n",
            "TRAIN loss : 3.21193    f1: 0.47831\n",
            "VALID loss : 3.20709    f1: 0.95738    best: 0.95738\n",
            "epoch : 30/85                time : 95s/5239s\n",
            "TRAIN loss : 3.21185    f1: 0.49691\n",
            "VALID loss : 3.20679    f1: 0.95454    best: 0.95738\n",
            "epoch : 31/85                time : 95s/5147s\n",
            "TRAIN loss : 3.21162    f1: 0.48939\n",
            "VALID loss : 3.20662    f1: 0.94486    best: 0.95738\n",
            "epoch : 32/85                time : 97s/5118s\n",
            "TRAIN loss : 3.21174    f1: 0.49158\n",
            "VALID loss : 3.20674    f1: 0.95610    best: 0.95738\n",
            "epoch : 33/85                time : 95s/4950s\n",
            "TRAIN loss : 3.21161    f1: 0.49384\n",
            "VALID loss : 3.20685    f1: 0.95797    best: 0.95797\n",
            "epoch : 34/85                time : 95s/4850s\n",
            "TRAIN loss : 3.21177    f1: 0.48548\n",
            "VALID loss : 3.20697    f1: 0.96716    best: 0.96716\n",
            "epoch : 35/85                time : 95s/4726s\n",
            "TRAIN loss : 3.21154    f1: 0.49673\n",
            "VALID loss : 3.20691    f1: 0.95925    best: 0.96716\n",
            "epoch : 36/85                time : 97s/4758s\n",
            "TRAIN loss : 3.21170    f1: 0.49449\n",
            "VALID loss : 3.20679    f1: 0.95316    best: 0.96716\n",
            "epoch : 37/85                time : 96s/4628s\n",
            "TRAIN loss : 3.21162    f1: 0.49970\n",
            "VALID loss : 3.20679    f1: 0.95189    best: 0.96716\n",
            "epoch : 38/85                time : 94s/4411s\n",
            "TRAIN loss : 3.21159    f1: 0.49063\n",
            "VALID loss : 3.20721    f1: 0.96643    best: 0.96716\n",
            "epoch : 39/85                time : 95s/4353s\n",
            "TRAIN loss : 3.21153    f1: 0.50334\n",
            "VALID loss : 3.20662    f1: 0.96759    best: 0.96759\n",
            "epoch : 40/85                time : 95s/4289s\n",
            "TRAIN loss : 3.21142    f1: 0.50952\n",
            "VALID loss : 3.20703    f1: 0.95947    best: 0.96759\n",
            "epoch : 41/85                time : 94s/4157s\n",
            "TRAIN loss : 3.21154    f1: 0.50128\n",
            "VALID loss : 3.20685    f1: 0.96586    best: 0.96759\n",
            "epoch : 42/85                time : 94s/4035s\n",
            "TRAIN loss : 3.21144    f1: 0.49601\n",
            "VALID loss : 3.20674    f1: 0.96828    best: 0.96828\n",
            "epoch : 43/85                time : 98s/4121s\n",
            "TRAIN loss : 3.21149    f1: 0.49874\n",
            "VALID loss : 3.20679    f1: 0.96653    best: 0.96828\n",
            "epoch : 44/85                time : 94s/3850s\n",
            "TRAIN loss : 3.21139    f1: 0.49737\n",
            "VALID loss : 3.20679    f1: 0.96311    best: 0.96828\n",
            "epoch : 45/85                time : 95s/3816s\n",
            "TRAIN loss : 3.21127    f1: 0.50477\n",
            "VALID loss : 3.20691    f1: 0.96027    best: 0.96828\n",
            "epoch : 46/85                time : 95s/3697s\n",
            "TRAIN loss : 3.21120    f1: 0.50326\n",
            "VALID loss : 3.20638    f1: 0.96847    best: 0.96847\n",
            "epoch : 47/85                time : 96s/3647s\n",
            "TRAIN loss : 3.21124    f1: 0.50478\n",
            "VALID loss : 3.20650    f1: 0.96525    best: 0.96847\n",
            "epoch : 48/85                time : 96s/3537s\n",
            "TRAIN loss : 3.21144    f1: 0.50131\n",
            "VALID loss : 3.20679    f1: 0.96525    best: 0.96847\n",
            "epoch : 49/85                time : 94s/3371s\n",
            "TRAIN loss : 3.21135    f1: 0.49778\n",
            "VALID loss : 3.20691    f1: 0.96377    best: 0.96847\n",
            "epoch : 50/85                time : 93s/3248s\n",
            "TRAIN loss : 3.21139    f1: 0.49899\n",
            "VALID loss : 3.20691    f1: 0.96816    best: 0.96847\n",
            "epoch : 51/85                time : 97s/3297s\n",
            "TRAIN loss : 3.21137    f1: 0.50207\n",
            "VALID loss : 3.20691    f1: 0.95665    best: 0.96847\n",
            "epoch : 52/85                time : 95s/3148s\n",
            "TRAIN loss : 3.21125    f1: 0.49938\n",
            "VALID loss : 3.20691    f1: 0.96103    best: 0.96847\n",
            "epoch : 53/85                time : 96s/3080s\n",
            "TRAIN loss : 3.21119    f1: 0.51585\n",
            "VALID loss : 3.20691    f1: 0.96597    best: 0.96847\n",
            "epoch : 54/85                time : 95s/2943s\n",
            "TRAIN loss : 3.21124    f1: 0.51015\n",
            "VALID loss : 3.20674    f1: 0.96082    best: 0.96847\n",
            "epoch : 55/85                time : 95s/2836s\n",
            "TRAIN loss : 3.21132    f1: 0.50946\n",
            "VALID loss : 3.20697    f1: 0.96563    best: 0.96847\n",
            "epoch : 56/85                time : 94s/2719s\n",
            "TRAIN loss : 3.21107    f1: 0.50796\n",
            "VALID loss : 3.20697    f1: 0.96273    best: 0.96847\n",
            "epoch : 57/85                time : 97s/2703s\n",
            "TRAIN loss : 3.21119    f1: 0.50466\n",
            "VALID loss : 3.20697    f1: 0.95676    best: 0.96847\n",
            "epoch : 58/85                time : 95s/2561s\n",
            "TRAIN loss : 3.21093    f1: 0.51653\n",
            "VALID loss : 3.20715    f1: 0.96269    best: 0.96847\n",
            "epoch : 59/85                time : 96s/2496s\n",
            "TRAIN loss : 3.21105    f1: 0.51763\n",
            "VALID loss : 3.20662    f1: 0.96296    best: 0.96847\n",
            "epoch : 60/85                time : 95s/2366s\n",
            "TRAIN loss : 3.21113    f1: 0.51177\n",
            "VALID loss : 3.20697    f1: 0.96388    best: 0.96847\n",
            "epoch : 61/85                time : 97s/2323s\n",
            "TRAIN loss : 3.21116    f1: 0.50371\n",
            "VALID loss : 3.20668    f1: 0.96190    best: 0.96847\n",
            "epoch : 62/85                time : 95s/2195s\n",
            "TRAIN loss : 3.21127    f1: 0.51037\n",
            "VALID loss : 3.20668    f1: 0.96296    best: 0.96847\n",
            "epoch : 63/85                time : 95s/2091s\n",
            "TRAIN loss : 3.21101    f1: 0.51602\n",
            "VALID loss : 3.20638    f1: 0.95884    best: 0.96847\n",
            "epoch : 64/85                time : 94s/1981s\n",
            "TRAIN loss : 3.21128    f1: 0.51357\n",
            "VALID loss : 3.20668    f1: 0.96298    best: 0.96847\n",
            "epoch : 65/85                time : 95s/1894s\n",
            "TRAIN loss : 3.21103    f1: 0.52256\n",
            "VALID loss : 3.20662    f1: 0.96759    best: 0.96847\n",
            "epoch : 66/85                time : 95s/1810s\n",
            "TRAIN loss : 3.21094    f1: 0.51512\n",
            "VALID loss : 3.20662    f1: 0.96843    best: 0.96847\n",
            "epoch : 67/85                time : 95s/1719s\n",
            "TRAIN loss : 3.21096    f1: 0.51516\n",
            "VALID loss : 3.20674    f1: 0.95874    best: 0.96847\n",
            "epoch : 68/85                time : 95s/1617s\n",
            "TRAIN loss : 3.21136    f1: 0.50562\n",
            "VALID loss : 3.20697    f1: 0.96477    best: 0.96847\n",
            "epoch : 69/85                time : 96s/1541s\n",
            "TRAIN loss : 3.21107    f1: 0.50897\n",
            "VALID loss : 3.20668    f1: 0.96818    best: 0.96847\n",
            "epoch : 70/85                time : 95s/1425s\n",
            "TRAIN loss : 3.21117    f1: 0.51279\n",
            "VALID loss : 3.20709    f1: 0.97574    best: 0.97574\n",
            "epoch : 71/85                time : 96s/1351s\n",
            "TRAIN loss : 3.21088    f1: 0.51541\n",
            "VALID loss : 3.20691    f1: 0.97045    best: 0.97574\n",
            "epoch : 72/85                time : 95s/1232s\n",
            "TRAIN loss : 3.21096    f1: 0.53105\n",
            "VALID loss : 3.20691    f1: 0.96131    best: 0.97574\n",
            "epoch : 73/85                time : 96s/1153s\n",
            "TRAIN loss : 3.21103    f1: 0.52151\n",
            "VALID loss : 3.20662    f1: 0.95915    best: 0.97574\n",
            "epoch : 74/85                time : 95s/1045s\n",
            "TRAIN loss : 3.21116    f1: 0.50478\n",
            "VALID loss : 3.20697    f1: 0.96923    best: 0.97574\n",
            "epoch : 75/85                time : 96s/963s\n",
            "TRAIN loss : 3.21085    f1: 0.53616\n",
            "VALID loss : 3.20662    f1: 0.96213    best: 0.97574\n",
            "epoch : 76/85                time : 94s/842s\n",
            "TRAIN loss : 3.21120    f1: 0.51269\n",
            "VALID loss : 3.20650    f1: 0.96624    best: 0.97574\n",
            "epoch : 77/85                time : 94s/753s\n",
            "TRAIN loss : 3.21114    f1: 0.51062\n",
            "VALID loss : 3.20668    f1: 0.96384    best: 0.97574\n",
            "epoch : 78/85                time : 94s/661s\n",
            "TRAIN loss : 3.21096    f1: 0.52221\n",
            "VALID loss : 3.20668    f1: 0.97243    best: 0.97574\n",
            "epoch : 79/85                time : 96s/573s\n",
            "TRAIN loss : 3.21120    f1: 0.51395\n",
            "VALID loss : 3.20638    f1: 0.96730    best: 0.97574\n",
            "epoch : 80/85                time : 94s/469s\n",
            "TRAIN loss : 3.21108    f1: 0.51761\n",
            "VALID loss : 3.20727    f1: 0.96670    best: 0.97574\n",
            "epoch : 81/85                time : 95s/380s\n",
            "TRAIN loss : 3.21111    f1: 0.50823\n",
            "VALID loss : 3.20715    f1: 0.96489    best: 0.97574\n",
            "epoch : 82/85                time : 95s/285s\n",
            "TRAIN loss : 3.21096    f1: 0.52379\n",
            "VALID loss : 3.20668    f1: 0.96556    best: 0.97574\n",
            "epoch : 83/85                time : 94s/188s\n",
            "TRAIN loss : 3.21117    f1: 0.51626\n",
            "VALID loss : 3.20703    f1: 0.97089    best: 0.97574\n",
            "epoch : 84/85                time : 95s/95s\n",
            "TRAIN loss : 3.21111    f1: 0.51824\n",
            "VALID loss : 3.20703    f1: 0.96234    best: 0.97574\n",
            "epoch : 85/85                time : 97s/0s\n",
            "TRAIN loss : 3.21100    f1: 0.52537\n",
            "VALID loss : 3.20626    f1: 0.97261    best: 0.97574\n"
          ]
        }
      ],
      "source": [
        "best_valid_f1 = 0\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "    model.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "        env = torch.tensor(batch[1], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[2], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(img, env)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "        gscaler.scale(loss).backward()\n",
        "        gscaler.step(optimizer)\n",
        "        gscaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "    train_f1 = accuracy_function(train_y, train_pred)\n",
        "    \n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_pred=[]\n",
        "    valid_y=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in (valid_loader):\n",
        "            img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "            env = torch.tensor(batch[1], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor(batch[2], dtype=torch.long, device=device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                pred = model(img, env)\n",
        "            loss = criterion(pred, y)\n",
        "            valid_loss += loss.item()/len(valid_loader)\n",
        "            valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "            valid_y += y.detach().cpu().numpy().tolist()\n",
        "        valid_f1 = accuracy_function(valid_y, valid_pred)\n",
        "    if valid_f1 >= best_valid_f1:\n",
        "        best_valid_f1 = valid_f1\n",
        "        torch.save(model.state_dict(), model_save_path + model_save_name)\n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}                time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'TRAIN loss : {train_loss:.5f}    f1: {train_f1:.5f}')\n",
        "    print(f'VALID loss : {valid_loss:.5f}    f1: {valid_f1:.5f}    best: {best_valid_f1:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fCqY5MfH3orS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ztor2_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}