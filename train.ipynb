{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CpxfkuI5XeV"
   },
   "source": [
    "#### 경로 설정 & 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qJjYyJz8O9Lw"
   },
   "outputs": [],
   "source": [
    "model_save_path =  'data/'\n",
    "model_save_name = 'model_name.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2l75gjNw0dEf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from skimage.transform import warp, rotate, AffineTransform, ProjectiveTransform\n",
    "from skimage.util import random_noise\n",
    "from scipy import ndimage\n",
    "\n",
    "import timm\n",
    "from timm.data.auto_augment import auto_augment_transform\n",
    "from timm.data.auto_augment import rand_augment_transform\n",
    "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
    "from PIL import Image\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BudB_UF8O9Ly"
   },
   "outputs": [],
   "source": [
    "train_csv = sorted(glob('data/train/*/*.csv'))\n",
    "train_jpg = sorted(glob('data/train/*/*.jpg'))\n",
    "train_json = sorted(glob('data/train/*/*.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUHhP_gDIJFs"
   },
   "source": [
    "#### 데이터 전처리 & 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiSRUlExHQt4"
   },
   "source": [
    "- 환경 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY4ngEfNXyxY"
   },
   "outputs": [],
   "source": [
    "max_len = 600\n",
    "csv_features = ['내부 온도 1 평균', '내부 습도 1 평균', '내부 이슬점 평균']\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfzWFkEc98fo",
    "outputId": "2a619444-0bb6-4636-bb85-6b8bf78d81fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5766/5766 [02:16<00:00, 42.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(num_row, num_feat): (1772360, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_env = pd.read_csv(train_csv[0])[csv_features]\n",
    "first_env = first_env.replace('-',np.nan)\n",
    "first_env = pd.DataFrame(imputer.fit_transform(first_env))\n",
    "env_concat = first_env.astype(float).diff().iloc[1:].values\n",
    "for csv_path in tqdm(train_csv[1:]):\n",
    "    tmp = pd.read_csv(csv_path)[csv_features]\n",
    "    tmp = tmp.replace('-', np.nan)\n",
    "    tmp = pd.DataFrame(imputer.fit_transform(tmp))\n",
    "    tmp = tmp.astype(float).diff().replace(np.nan, 0.).values\n",
    "    if len(tmp) <= 1:\n",
    "        continue\n",
    "    env_concat = np.vstack((env_concat, tmp[1:]))\n",
    "print('\\n(num_row, num_feat): ', env_concat.shape, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOCglEs7GJSo"
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler().fit(env_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQh1ip4KInzH"
   },
   "outputs": [],
   "source": [
    "def prepro_csv(csv_file, max_len=200):\n",
    "    df = pd.read_csv(csv_file)[csv_features]\n",
    "    df = df.replace('-', np.nan).dropna()\n",
    "    df = pd.DataFrame(df).astype(float).diff()\n",
    "    df = df.replace(np.nan, 0.)\n",
    "    scaled = scaler.transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled)\n",
    "    pad = np.zeros((max_len, len(scaled_df.columns)))\n",
    "    length = min(max_len, len(scaled_df))\n",
    "    pad[-length:] = scaled_df.to_numpy()[-length:]\n",
    "    env_output = np.round(pad.T, 6)\n",
    "    return env_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbhdoZBuHLt_"
   },
   "source": [
    "- 레이블 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zYCpJLE0tHR",
    "outputId": "28808dd6-36e6-4ac7-b67b-3f3382a70d6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5767"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops = []\n",
    "diseases = []\n",
    "risks = []\n",
    "labels_str = []\n",
    "for i in range(len(train_json)):\n",
    "    with open(train_json[i], 'r') as f:\n",
    "        sample = json.load(f)\n",
    "        crop = sample['annotations']['crop']\n",
    "        disease = sample['annotations']['disease']\n",
    "        risk = sample['annotations']['risk']\n",
    "        label=f\"{crop}_{disease}_{risk}\"  \n",
    "        crops.append(crop)\n",
    "        diseases.append(disease)\n",
    "        risks.append(risk)\n",
    "        labels_str.append(label)\n",
    "label2int = sorted(np.unique(labels_str))\n",
    "label2int = {key:value for key,value in zip(label2int, range(len(label2int)))}\n",
    "labels = [label2int[k] for k in labels_str]\n",
    "int2label = {}\n",
    "for key, value in label2int .items():\n",
    "    int2label[value] = key\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcnQlz7dHXr7"
   },
   "source": [
    "- 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMt-PeG-whRy"
   },
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HimDLnjWFxqU",
    "outputId": "f1eb49e7-2b64-447b-f44a-2ab3fdcac8bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5767/5767 [00:46<00:00, 124.07it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "for i in tqdm(train_jpg):\n",
    "    imgs.append(img_load(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "See5lv-Pyd3y",
    "outputId": "53fa135c-3149-41fc-b415-b58bce1ffb00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5767/5767 [00:55<00:00, 103.88it/s]\n"
     ]
    }
   ],
   "source": [
    "envs = []\n",
    "for i in tqdm(train_csv):\n",
    "    envs.append(prepro_csv(i, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysPIEd5Sgmba"
   },
   "outputs": [],
   "source": [
    "bbxs = []\n",
    "for i in range(len(train_json)):\n",
    "    with open(train_json[i], 'r') as f:\n",
    "        tmp = json.load(f)\n",
    "    X = int(tmp['annotations']['bbox'][0]['x'])\n",
    "    H = int(tmp['annotations']['bbox'][0]['h'])\n",
    "    Y = int(tmp['annotations']['bbox'][0]['y'])\n",
    "    W = int(tmp['annotations']['bbox'][0]['w'])\n",
    "    bbxs.append([X, X+W, Y, Y+H])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geAlmDeaaxAr"
   },
   "outputs": [],
   "source": [
    "part = []\n",
    "for i in range(len(train_json)):\n",
    "    with open(train_json[i], 'r') as f:\n",
    "        tmp = json.load(f)\n",
    "    num_part = len(tmp['annotations']['part'])\n",
    "    if num_part == 0:\n",
    "        part.append([])\n",
    "    else:\n",
    "        sub_list = []\n",
    "        for i in range(num_part):\n",
    "            X = int(tmp['annotations']['part'][i]['x'])\n",
    "            H = int(tmp['annotations']['part'][i]['h'])\n",
    "            Y = int(tmp['annotations']['part'][i]['y'])\n",
    "            W = int(tmp['annotations']['part'][i]['w'])\n",
    "            sub_list.append([X, X+W, Y, Y+H])\n",
    "        part.append(sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvoxos4NgkIw",
    "outputId": "8c083997-6d66-4f63-93b6-9a9056914d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5767 5767 5767 5767 5767\n"
     ]
    }
   ],
   "source": [
    "print(len(imgs), len(envs), len(labels), len(bbxs), len(part))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKxjH-c3GEDW"
   },
   "source": [
    "#### 데이터 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8A-XaM34_5uk",
    "outputId": "8fd5b181-b239-4d59-f74b-90e68ceeb27e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label frequency\n",
       "0               810\n",
       "1               143\n",
       "2               189\n",
       "3              1177\n",
       "4               154\n",
       "5               111\n",
       "6                42\n",
       "7               166\n",
       "8               142\n",
       "9               156\n",
       "10              153\n",
       "11              917\n",
       "12               69\n",
       "13               99\n",
       "14              148\n",
       "15              159\n",
       "16              157\n",
       "17              828\n",
       "18               40\n",
       "19               12\n",
       "20               13\n",
       "21               29\n",
       "22               18\n",
       "23               14\n",
       "24               21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = {i:labels.count(i) for i in set(labels)}\n",
    "freqdf = pd.DataFrame(freq.values(), columns=['Label frequency']); freqdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWmUHOd4AVlr",
    "outputId": "cfc1caa2-cdc7-4a99-d433-b38b993dbbce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 20 22 23]\n",
      "[ 6 18 21 24]\n",
      "[12]\n"
     ]
    }
   ],
   "source": [
    "imbalance_label_1 = np.unique([i for i in labels if freq[i] < 20])\n",
    "imbalance_label_2 = np.unique([i for i in labels if freq[i] >= 20 and freq[i] <= 42])\n",
    "imbalance_label_3 = np.unique([i for i in labels if freq[i] > 42 and freq[i] < 70])\n",
    "print(imbalance_label_1, '\\n', imbalance_label_2, '\\n', imbalance_label_3, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfhRuhDTAwr8"
   },
   "outputs": [],
   "source": [
    "oversample_num_1 = 12\n",
    "oversample_num_2 = 5\n",
    "oversample_num_3 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzhJvaBsyFTB"
   },
   "outputs": [],
   "source": [
    "imgs_oversampled = imgs.copy()\n",
    "envs_oversampled = envs.copy()\n",
    "labels_oversampled = labels.copy()\n",
    "bbxs_oversampled = bbxs.copy()\n",
    "part_oversampled = part.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJYtLFECA084",
    "outputId": "f5570c84-dbc6-4a7b-b452-ac670a030198"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 5767/5767 [00:00<00:00, 122956.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, label in enumerate(tqdm(labels)):\n",
    "    if label in imbalance_label_1:\n",
    "        for i in range(oversample_num_1):\n",
    "            imgs_oversampled.append(imgs[idx])\n",
    "            envs_oversampled.append(envs[idx])\n",
    "            labels_oversampled.append(label)\n",
    "            bbxs_oversampled.append(bbxs[idx])\n",
    "            part_oversampled.append(part[idx])\n",
    "    elif label in imbalance_label_2:\n",
    "        for i in range(oversample_num_2):\n",
    "            imgs_oversampled.append(imgs[idx])\n",
    "            envs_oversampled.append(envs[idx])\n",
    "            labels_oversampled.append(label)\n",
    "            bbxs_oversampled.append(bbxs[idx])\n",
    "            part_oversampled.append(part[idx])\n",
    "    elif label in imbalance_label_3:\n",
    "        for i in range(oversample_num_3):\n",
    "            imgs_oversampled.append(imgs[idx])\n",
    "            envs_oversampled.append(envs[idx])\n",
    "            labels_oversampled.append(label)\n",
    "            bbxs_oversampled.append(bbxs[idx])\n",
    "            part_oversampled.append(part[idx])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lI6TBtHhu_kL",
    "outputId": "b1c33168-6670-4a05-aa1d-d7458037a77d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label frequency\n",
       "0               810\n",
       "1               143\n",
       "2               189\n",
       "3              1177\n",
       "4               154\n",
       "5               111\n",
       "6               252\n",
       "7               166\n",
       "8               142\n",
       "9               156\n",
       "10              153\n",
       "11              917\n",
       "12              207\n",
       "13               99\n",
       "14              148\n",
       "15              159\n",
       "16              157\n",
       "17              828\n",
       "18              240\n",
       "19              156\n",
       "20              169\n",
       "21              174\n",
       "22              234\n",
       "23              182\n",
       "24              126"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_oversampled = {i:labels_oversampled.count(i) for i in set(labels_oversampled)}\n",
    "freqdf_oversampled = pd.DataFrame(freq_oversampled.values(), columns=['Label frequency']); freqdf_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kAJXiueBeFV",
    "outputId": "ec99cd42-aa9a-478a-a4da-e2fe797088e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7249 7249 7249 7249 7249\n"
     ]
    }
   ],
   "source": [
    "print(len(imgs_oversampled), len(envs_oversampled), len(labels_oversampled), len(bbxs_oversampled), len(part_oversampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5JScupoHdfp"
   },
   "source": [
    "#### 데이터 증강 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZS99RB5bpHW"
   },
   "outputs": [],
   "source": [
    "img_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkFZUOTZlMzm"
   },
   "outputs": [],
   "source": [
    "def randRange(a, b):\n",
    "    return np.round(np.random.rand() * (b - a) + a,  2)\n",
    "def rotation(img): \n",
    "    rotated_img = rotate(img, angle=random.choice([-15, 15, 30, -30, 90, -90]))\n",
    "    norm_image = cv2.normalize(rotated_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    rotated_img = norm_image.astype(np.uint8)\n",
    "    return rotated_img\n",
    "def up_down(img):\n",
    "    return np.flipud(img)\n",
    "def left_right(img):\n",
    "    return np.fliplr(img)\n",
    "def noise(img):\n",
    "    noised_img = random_noise(img, var=random.choice([3e-2, 3e-3]))\n",
    "    norm_image = cv2.normalize(noised_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    noised_img = norm_image.astype(np.uint8)\n",
    "    return noised_img\n",
    "def brightness(img):\n",
    "    return img + random.choice([20, 30, 40])\n",
    "def contrast(img):\n",
    "    contrasted_img = img * random.choice([5e-3, 6e-3])\n",
    "    norm_image = cv2.normalize(contrasted_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    contrasted_img = norm_image.astype(np.uint8)\n",
    "    return contrasted_img\n",
    "def blur(img):\n",
    "    return ndimage.uniform_filter(img, size=(random.choice([4, 6]), random.choice([4, 6]), random.choice([1, 1.3])))\n",
    "def random_affine(img):\n",
    "    tform = AffineTransform(scale=(randRange(0.75, 1.3), randRange(0.75, 1.3)),\n",
    "                                                   rotation=randRange(-0.25, 0.25),\n",
    "                                                   shear=randRange(-0.2, 0.2),\n",
    "                                                   translation=(randRange(-img.shape[0]//10, img.shape[0]//10), \n",
    "                                                   randRange(-img.shape[1]//10, img.shape[1]//10)))\n",
    "    affined_img = np.float32(warp(img, tform.inverse, mode='reflect'))\n",
    "    norm_image = cv2.normalize(affined_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    affined_img = norm_image.astype(np.uint8)\n",
    "    return affined_img\n",
    "def random_perspective(img):\n",
    "    region = 1/4\n",
    "    A = np.array([[0, 0], [0, img.shape[0]], [img.shape[1], img.shape[0]], [img.shape[1], 0]])\n",
    "    B = np.array([[int(randRange(0, img.shape[1] * region)), int(randRange(0, img.shape[0] * region))], \n",
    "                            [int(randRange(0, img.shape[1] * region)), int(randRange(img.shape[0] * (1-region), img.shape[0]))], \n",
    "                            [int(randRange(img.shape[1] * (1-region), img.shape[1])), int(randRange(img.shape[0] * (1-region), img.shape[0]))], \n",
    "                            [int(randRange(img.shape[1] * (1-region), img.shape[1])), int(randRange(0, img.shape[0] * region))], \n",
    "                            ])\n",
    "    pt = ProjectiveTransform()\n",
    "    pt.estimate(A, B)\n",
    "    \n",
    "    perspectived_img = np.float32(warp(img, pt, output_shape=img.shape[:2]))\n",
    "    norm_image = cv2.normalize(perspectived_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    perspectived_img = norm_image.astype(np.uint8)\n",
    "    return perspectived_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ggW-IzXlPed"
   },
   "outputs": [],
   "source": [
    "aug_func_list = [rotation, up_down, left_right, noise, brightness, contrast, blur, random_affine, random_perspective]\n",
    "def series_aug(img, aug_func_list):\n",
    "    num_func = random.choice(list(range(2, 7)))\n",
    "    chosen_func = random.sample(aug_func_list, num_func)\n",
    "    random.shuffle(chosen_func)\n",
    "    for func in chosen_func:\n",
    "        img = func(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BOcD1BP1bfi"
   },
   "outputs": [],
   "source": [
    "def skimg_aug(img):\n",
    "    img_augmented = series_aug(img, aug_func_list)\n",
    "    img_augmented_resized = cv2.resize(img_augmented, img_size)\n",
    "    return img_augmented_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuKaKrP0KABu"
   },
   "outputs": [],
   "source": [
    "autoaug = auto_augment_transform(config_str='original', hparams={'translate_const': 100, 'img_mean': (124, 116, 104)})\n",
    "randaug = rand_augment_transform(config_str='rand-m9-mstd0.5', hparams={'translate_const': 117, 'img_mean': (124, 116, 104)})\n",
    "resizecrop = RandomResizedCropAndInterpolation(size=random.choice([300, 400]))\n",
    "timm_func_list = [autoaug, randaug, resizecrop]\n",
    "def timm_aug(img):\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    chosen_func = random.sample(timm_func_list, random.choice([1, 2, 3]))\n",
    "    random.shuffle(chosen_func)\n",
    "    for func in chosen_func:\n",
    "        img = func(img)\n",
    "    img_augmented_resized = cv2.resize(np.array(img), img_size)\n",
    "    return img_augmented_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHo_em6HGS4M"
   },
   "outputs": [],
   "source": [
    "def mixup_aug(idx, beta):\n",
    "    sampled_idx = random.sample(list(train_idx), 1)[0]\n",
    "    img1 = cv2.resize(imgs_oversampled[idx], img_size)\n",
    "    img2 =  cv2.resize(imgs_oversampled[sampled_idx], img_size)\n",
    "    label1 = labels_oversampled[idx]\n",
    "    label2 = labels_oversampled[sampled_idx]\n",
    "    alpha= np.random.beta(beta, beta)\n",
    "    mixup_img = alpha * img1 /255 + (1-alpha) *  img2 /255\n",
    "    mixup_label = alpha * label1 + (1-alpha) * label2\n",
    "    norm_image = cv2.normalize(mixup_img, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    mixup_img = norm_image.astype(np.uint8)\n",
    "    return mixup_img, np.round(mixup_label, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5hKUI3PTtV1"
   },
   "outputs": [],
   "source": [
    "pre_torch_transformer = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                                                         transforms.RandomPosterize(bits=3, p=0.25),\n",
    "                                                                                         transforms.ColorJitter(brightness=randRange(0.15, 0.3), contrast=randRange(0.15, 0.3), saturation=randRange(0.15, 0.3), hue=randRange(0.15, 0.3)), # 밝기, 대비, 채도, 색조\n",
    "                                                                                         transforms.RandomInvert(p=0.1),\n",
    "                                                                                         transforms.RandomAdjustSharpness(random.choice([2, 4]), p=0.75)\n",
    "                                                                                         ])\n",
    "post_torch_transformer = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                                                         transforms.RandAugment(num_ops=random.randint(1, 4), magnitude=random.randint(1, 4))\n",
    "                                                                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0rl4TWckB1C"
   },
   "outputs": [],
   "source": [
    "def torch_aug_with_bbx(img, idx):\n",
    "    torch_augmented = np.array(pre_torch_transformer(img))\n",
    "    x1, x2, y1, y2 = bbxs_oversampled[idx]\n",
    "    mix_type = random.randint(0, 1)\n",
    "    post_aug = random.randint(0, 1)\n",
    "    if mix_type == 0:\n",
    "        torch_augmented[y1:y2,x1:x2] = img[y1:y2,x1:x2]\n",
    "        if post_aug == 1:\n",
    "            torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "        elif post_aug == 0:\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "    elif mix_type == 1:\n",
    "        img[y1:y2,x1:x2] = torch_augmented[y1:y2,x1:x2]\n",
    "        if post_aug == 1:\n",
    "            img = np.array(post_torch_transformer(img))\n",
    "            return cv2.resize(img, img_size)\n",
    "        elif post_aug == 0:\n",
    "            return cv2.resize(img, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN682zTkhNwY"
   },
   "outputs": [],
   "source": [
    "def torch_aug_with_part_bbx(img, idx):\n",
    "    torch_augmented = np.array(pre_torch_transformer(img))\n",
    "    part_list = part_oversampled[idx]\n",
    "    mix_type = random.randint(0, 1)\n",
    "    post_aug = random.randint(0, 1)\n",
    "    if len(part_list) == 0:\n",
    "        if post_aug == 1:\n",
    "            torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "        elif post_aug == 0:\n",
    "            return cv2.resize(torch_augmented, img_size)\n",
    "    else:\n",
    "        if mix_type == 0:\n",
    "            for i in range(len(part_list)):\n",
    "                x1, x2, y1, y2 = part_list[i]\n",
    "                torch_augmented[y1:y2,x1:x2] = img[y1:y2,x1:x2]\n",
    "            if post_aug == 1:\n",
    "                torch_augmented = np.array(post_torch_transformer(torch_augmented))\n",
    "                return cv2.resize(torch_augmented, img_size)\n",
    "            elif post_aug == 0:\n",
    "                return cv2.resize(torch_augmented, img_size)\n",
    "        elif mix_type == 1:\n",
    "            for i in range(len(part_list)):\n",
    "                x1, x2, y1, y2 = part_list[i]\n",
    "                img[y1:y2,x1:x2] = torch_augmented[y1:y2,x1:x2]\n",
    "            if post_aug == 1:\n",
    "                img = np.array(post_torch_transformer(img))\n",
    "                return cv2.resize(torch_augmented, img_size)\n",
    "            elif post_aug == 0:\n",
    "                return cv2.resize(img, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWQvvbqU2dlu"
   },
   "outputs": [],
   "source": [
    "def edge_aug(img):\n",
    "    edge_type = random.randint(0, 2)\n",
    "    post_aug = random.randint(0, 1)\n",
    "    if edge_type == 0:\n",
    "        edge = cv2.Canny(img, random.choice([60, 80]), random.choice([60, 80]))\n",
    "        edge = np.stack((edge,)*3, axis=-1)\n",
    "    elif edge_type == 1:\n",
    "        edge = cv2.Sobel(img, -1, 0, 1)\n",
    "    elif edge_type == 2:\n",
    "        edge = cv2.Laplacian(img, -1)\n",
    "    img_edge_added = edge + img\n",
    "    if post_aug == 1:\n",
    "        img_augmented = timm_aug(img_edge_added)\n",
    "    else:\n",
    "        img_augmented = img_edge_added\n",
    "    img_augmented_resized = cv2.resize(img_augmented, img_size)\n",
    "    return img_augmented_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emf01X4VM_v3"
   },
   "outputs": [],
   "source": [
    "def resize_only(img):\n",
    "    img_resized = cv2.resize(img, img_size)\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaHCBETMXnov"
   },
   "outputs": [],
   "source": [
    "def scaling(x, sigma=0.05):\n",
    "    factor = np.random.normal(loc=1., scale=sigma, size=x.shape)\n",
    "    return np.multiply(x, factor)\n",
    "def temporal_aug(envs):\n",
    "    aug = np.round(np.random.rand(), 2)\n",
    "    if aug >= 0.4:\n",
    "        df = pd.DataFrame(envs)\n",
    "        df_nonzero = df.loc[:, (df != 0).any(axis=0)]\n",
    "        df_nonzero_aug = scaling(df_nonzero)\n",
    "        df[df_nonzero_aug.columns] = df_nonzero_aug\n",
    "        return df.values\n",
    "    else:\n",
    "        return envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB1QWrgTHhKG"
   },
   "source": [
    "#### 모델 및  커스텀 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yExSdKLoFEw4"
   },
   "outputs": [],
   "source": [
    "num_class = len(np.unique(labels))\n",
    "rnn_hidden_dim = 512\n",
    "dropout_rate = 0.4\n",
    "cnn_output_dim = 1000\n",
    "rnn_output_dim = 128\n",
    "env_temporal_len = max_len\n",
    "env_feature_len = len(csv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6tYs4uLEqop"
   },
   "outputs": [],
   "source": [
    "class rnn_decoder(nn.Module):\n",
    "    def __init__(self, env_temporal_len, rnn_hidden_dim, rnn_output_dim, env_feature_len, num_class, dropout_rate):\n",
    "        super(rnn_decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(env_temporal_len, rnn_hidden_dim)\n",
    "        self.rnn_fc = nn.Linear(env_feature_len * rnn_hidden_dim, rnn_output_dim)\n",
    "        self.final_layer = nn.Linear(cnn_output_dim + rnn_output_dim, num_class)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, enc_out, dec_inp):\n",
    "        hidden, _ = self.lstm(dec_inp)\n",
    "        hidden = hidden.view(hidden.size(0), -1)\n",
    "        hidden = self.rnn_fc(hidden)\n",
    "        concat = torch.cat([enc_out, hidden], dim=1)\n",
    "        fc_input = concat\n",
    "        output = self.dropout((self.final_layer(fc_input)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6LCRVJyo4Jx"
   },
   "outputs": [],
   "source": [
    "image_model = 'tinynet_a' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLXiu5Fg31Ii"
   },
   "outputs": [],
   "source": [
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, imgs, envs, labels, mode='train'):\n",
    "        self.imgs = imgs\n",
    "        self.envs = envs\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        if self.mode=='train':\n",
    "            aug_type = random.randint(0, 6)\n",
    "            if aug_type in list(range(0, 1)):\n",
    "                img, label = mixup_aug(idx, beta=1)\n",
    "            elif aug_type in list(range(1, 2)):\n",
    "                img = timm_aug(img)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(2, 3)):\n",
    "                img = skimg_aug(img)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(3, 4)):\n",
    "                img = torch_aug_with_bbx(img, idx)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(4, 5)):\n",
    "                img = torch_aug_with_part_bbx(img, idx)\n",
    "                label = self.labels[idx]\n",
    "            elif aug_type in list(range(5, 6)):\n",
    "                img = edge_aug(img)\n",
    "                label = self.labels[idx]\n",
    "            else:\n",
    "                img = resize_only(img)\n",
    "                label = self.labels[idx]\n",
    "            img = transforms.ToTensor()(img)\n",
    "            envs = temporal_aug(self.envs[idx])\n",
    "            return img, envs, label\n",
    "        elif self.mode=='valid':\n",
    "            img = resize_only(img)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            envs = self.envs[idx]\n",
    "            label = self.labels[idx]\n",
    "            return img, envs, label\n",
    "        elif self.mode=='test':\n",
    "            img = resize_only(img)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            envs = self.envs[idx]\n",
    "            return img, envs\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        self.cnn = timm.create_model(image_model, pretrained=True)\n",
    "        self.rnn = rnn_decoder(env_temporal_len, rnn_hidden_dim, rnn_output_dim, env_feature_len, num_class, dropout_rate)\n",
    "\n",
    "    def forward(self, img, env):\n",
    "        x = self.cnn(img)\n",
    "        output = self.rnn(x, env)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcKulZvHLBpI",
    "outputId": "b41afc08-0a1e-47d6-c001-bba2084c202f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda'); device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpOgdhnjLCjV"
   },
   "outputs": [],
   "source": [
    "learning_rate = 4e-5\n",
    "label_smoothing = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUfxrZ2BLGy0"
   },
   "outputs": [],
   "source": [
    "model = network().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "gscaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oz8FBv7jNlzq"
   },
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    score = f1_score(real, pred, average='macro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0r2GPqOHr0S"
   },
   "source": [
    "#### 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjKkkpMaLQWb",
    "outputId": "229bbc50-5d9d-4dfb-9182-636006ac6de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train: 6213 num_val; 1036\n",
      "ratio_train: 0.86 ratio_val: 0.14\n"
     ]
    }
   ],
   "source": [
    "n_splits = 7\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=41)\n",
    "folds = [(train_idx, valid_idx) for train_idx, valid_idx in kf.split(imgs_oversampled, labels_oversampled)]\n",
    "train_idx, valid_idx = folds[0]\n",
    "train_imgs = list(map(imgs_oversampled.__getitem__, train_idx))\n",
    "train_envs = list(map(envs_oversampled.__getitem__, train_idx))\n",
    "train_labels = list(map(labels_oversampled.__getitem__, train_idx))\n",
    "val_imgs = list(map(imgs_oversampled.__getitem__, valid_idx))\n",
    "val_envs = list(map(envs_oversampled.__getitem__, valid_idx))\n",
    "val_labels = list(map(labels_oversampled.__getitem__, valid_idx))\n",
    "print('num_train: {} num_val; {}'.format(len(train_idx), len(valid_idx)))\n",
    "print('ratio_train: {} ratio_val: {}'.format(np.round(len(train_idx)/len(imgs_oversampled), 2), np.round(len(valid_idx)/len(imgs_oversampled), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce4yynwULQPV"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ulbcgOS6BVG"
   },
   "outputs": [],
   "source": [
    "train_dataset = custom_dataset(train_imgs, train_envs, train_labels, mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=8)\n",
    "\n",
    "valid_dataset = custom_dataset(val_imgs, val_envs, val_labels, mode='valid')\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0O4HK-iHxit"
   },
   "source": [
    "#### 학습 & 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QSYL29Eq6J2"
   },
   "outputs": [],
   "source": [
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RoArz69S6IZ1"
   },
   "outputs": [],
   "source": [
    "best_valid_f1 = 0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        env = torch.tensor(batch[1], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[2], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(img, env)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        gscaler.scale(loss).backward()\n",
    "        gscaler.step(optimizer)\n",
    "        gscaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "    train_f1 = accuracy_function(train_y, train_pred)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_pred=[]\n",
    "    valid_y=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in (valid_loader):\n",
    "            img = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "            env = torch.tensor(batch[1], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(batch[2], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(img, env)\n",
    "            loss = criterion(pred, y)\n",
    "            valid_loss += loss.item()/len(valid_loader)\n",
    "            valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            valid_y += y.detach().cpu().numpy().tolist()\n",
    "        valid_f1 = accuracy_function(valid_y, valid_pred)\n",
    "    if valid_f1 >= best_valid_f1:\n",
    "        best_valid_f1 = valid_f1\n",
    "        torch.save(model.state_dict(), model_save_path + model_save_name)\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}                time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN loss : {train_loss:.5f}    f1: {train_f1:.5f}')\n",
    "    print(f'VALID loss : {valid_loss:.5f}    f1: {valid_f1:.5f}    best: {best_valid_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCqY5MfH3orS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [
    "V0r2GPqOHr0S"
   ],
   "machine_shape": "hm",
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
